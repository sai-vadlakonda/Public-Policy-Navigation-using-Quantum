{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c5e79b6-1b14-4c46-a9b4-582b67df59e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pennylane'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpennylane\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mqml\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpennylane\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m numpy \u001b[38;5;28;01mas\u001b[39;00m np\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pennylane'"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    " \n",
    "# ---- Output paths ----\n",
    "TFIDF_MODEL_PATH = \"quantum_policy_vectorizer.pkl\"\n",
    "QUANTUM_MATRIX_PATH = \"quantum_policy_tfidf_matrix.pkl\"\n",
    " \n",
    "# ---- Step 1: Load datasets ----\n",
    "train_df = pd.read_csv(\"train_policies.csv\")\n",
    "full_df = pd.read_csv(\"education_policies.csv\")\n",
    " \n",
    "# ---- Step 2: Preprocess data ----\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    df[\"text_for_nlp\"] = (\n",
    "        df[\"title\"].astype(str) + \". \" +\n",
    "        df[\"full_text\"].astype(str) + \". Stakeholders: \" +\n",
    "        df[\"stakeholders\"].astype(str)\n",
    "    ).str.lower()\n",
    "    return df\n",
    "\n",
    "train_df = preprocess(train_df)\n",
    "full_df = preprocess(full_df)\n",
    "\n",
    "# ---- Step 3: Classical TF-IDF ----\n",
    "# Use small max_features for quantum demonstration (e.g., 8 qubits)\n",
    "vectorizer = TfidfVectorizer(max_features=8, ngram_range=(1, 1))\n",
    "vectorizer.fit(train_df[\"text_for_nlp\"])\n",
    "tfidf_matrix = vectorizer.transform(full_df[\"text_for_nlp\"]).toarray()\n",
    "tfidf_matrix = normalize(tfidf_matrix, norm=\"l2\")  # Normalize for quantum embedding\n",
    " \n",
    "# ---- Step 4: Quantum device setup ----\n",
    "n_qubits = tfidf_matrix.shape[1]\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    " \n",
    "# ---- Step 5: Define quantum feature encoder ----\n",
    "@qml.qnode(dev)\n",
    "def quantum_encoder(x):\n",
    "    # Encode classical TF-IDF vector into qubit rotations\n",
    "    qml.templates.AngleEmbedding(x, wires=range(n_qubits))\n",
    "    qml.templates.BasicEntanglerLayers(weights=np.ones((1, n_qubits)), wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "    \n",
    "# ---- Step 6: Encode all samples ----\n",
    "quantum_features = np.array([quantum_encoder(x) for x in tfidf_matrix])\n",
    " \n",
    "# ---- Step 7: Save both classical and quantum components ----\n",
    "# Save TF-IDF vectorizer\n",
    "joblib.dump(vectorizer, TFIDF_MODEL_PATH)\n",
    "\n",
    "# Save quantum features and metadata\n",
    "joblib.dump({\n",
    "    \"quantum_features\": quantum_features,\n",
    "    \"tfidf_matrix\": tfidf_matrix,\n",
    "    \"df\": full_df\n",
    "}, QUANTUM_MATRIX_PATH)\n",
    "\n",
    "print(f\"âœ… Quantum TF-IDF model saved to '{TFIDF_MODEL_PATH}'\")\n",
    "print(f\"âœ… Quantum feature matrix saved to '{QUANTUM_MATRIX_PATH}'\")\n",
    " \n",
    "import textwrap\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    " \n",
    "# --------------------------------------------------\n",
    "# Load quantum TF-IDF model and quantum embeddings\n",
    "# --------------------------------------------------\n",
    "\n",
    "TFIDF_MODEL_PATH = \"quantum_policy_vectorizer.pkl\"\n",
    "QUANTUM_MATRIX_PATH = \"quantum_policy_tfidf_matrix.pkl\"\n",
    " \n",
    "vectorizer = joblib.load(TFIDF_MODEL_PATH)\n",
    "data = joblib.load(QUANTUM_MATRIX_PATH)\n",
    " \n",
    "quantum_features = data[\"quantum_features\"]\n",
    "tfidf_matrix = data[\"tfidf_matrix\"]\n",
    "\n",
    "df = data[\"df\"]\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Quantum device setup\n",
    "# --------------------------------------------------\n",
    "\n",
    "n_qubits = tfidf_matrix.shape[1]\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "@qml.qnode(dev)\n",
    "\n",
    "def quantum_encoder(x):\n",
    "    \"\"\"Quantum feature map: encodes a classical TF-IDF vector into qubits\"\"\"\n",
    "    qml.templates.AngleEmbedding(x, wires=range(n_qubits))\n",
    "    qml.templates.BasicEntanglerLayers(weights=np.ones((1, n_qubits)), wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    " \n",
    "# --------------------------------------------------\n",
    "# Quantum search function\n",
    "# --------------------------------------------------\n",
    "\n",
    "def answer_query(query, top_k=3):\n",
    "    \"\"\"Find top-k policies most similar to the query (quantum TF-IDF encoding).\"\"\"\n",
    "    # Step 1: Classical TF-IDF of query\n",
    "    query_vec = vectorizer.transform([query.lower()]).toarray()\n",
    "    query_vec = normalize(query_vec, norm=\"l2\")\n",
    "    # Step 2: Quantum encode the query\n",
    "    query_quantum = np.array(quantum_encoder(query_vec[0]))\n",
    "    # Step 3: Compute similarity with stored quantum features\n",
    "    sims = cosine_similarity([query_quantum], quantum_features).flatten()\n",
    "    top_idx = sims.argsort()[::-1][:top_k]\n",
    "\n",
    "    # Step 4: Display results\n",
    "    print(f\"\\nðŸ”Ž Quantum Query: {query}\")\n",
    "    for idx in top_idx:\n",
    "        row = df.iloc[idx]\n",
    "        snippet = textwrap.shorten(row[\"full_text\"], width=250, placeholder=\"...\")\n",
    "        print(f\"\\nðŸ“Œ {row['title']} ({row['policy_id']}) | Quantum Similarity = {sims[idx]:.3f}\")\n",
    "        print(f\"Region: {row['region']} | Year: {row['year']} | Status: {row['status']}\")\n",
    "        print(f\"Summary: {snippet}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Example query\n",
    "# --------------------------------------------------\n",
    "answer_query(\"teacher training and capacity building initiatives\", top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f13711f8-5134-42b7-9094-4a4818c1e85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pennylane\n",
      "  Downloading pennylane-0.42.3-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\pavan kumar\\desktop\\qnpl-env\\lib\\site-packages (from pennylane) (1.15.3)\n",
      "Collecting networkx (from pennylane)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: rustworkx>=0.14.0 in c:\\users\\pavan kumar\\desktop\\qnpl-env\\lib\\site-packages (from pennylane) (0.17.1)\n",
      "Collecting autograd (from pennylane)\n",
      "  Downloading autograd-1.8.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting appdirs (from pennylane)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting autoray<0.8,>=0.6.11 (from pennylane)\n",
      "  Downloading autoray-0.7.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting cachetools (from pennylane)\n",
      "  Downloading cachetools-6.2.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting pennylane-lightning>=0.42 (from pennylane)\n",
      "  Downloading pennylane_lightning-0.42.0-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\pavan kumar\\desktop\\qnpl-env\\lib\\site-packages (from pennylane) (2.32.5)\n",
      "Collecting tomlkit (from pennylane)\n",
      "  Downloading tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\pavan kumar\\desktop\\qnpl-env\\lib\\site-packages (from pennylane) (4.15.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pavan kumar\\desktop\\qnpl-env\\lib\\site-packages (from pennylane) (25.0)\n",
      "Collecting diastatic-malt (from pennylane)\n",
      "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\pavan kumar\\desktop\\qnpl-env\\lib\\site-packages (from pennylane) (2.2.6)\n",
      "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.42->pennylane)\n",
      "  Downloading scipy_openblas32-0.3.30.0.4-py3-none-win_amd64.whl.metadata (56 kB)\n",
      "Collecting astunparse (from diastatic-malt->pennylane)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting gast (from diastatic-malt->pennylane)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting termcolor (from diastatic-malt->pennylane)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse->diastatic-malt->pennylane)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: six<2.0,>=1.6.1 in c:\\users\\pavan kumar\\desktop\\qnpl-env\\lib\\site-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\pavan kumar\\desktop\\qnpl-env\\lib\\site-packages (from requests->pennylane) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pavan kumar\\desktop\\qnpl-env\\lib\\site-packages (from requests->pennylane) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pavan kumar\\desktop\\qnpl-env\\lib\\site-packages (from requests->pennylane) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pavan kumar\\desktop\\qnpl-env\\lib\\site-packages (from requests->pennylane) (2025.10.5)\n",
      "Downloading pennylane-0.42.3-py3-none-any.whl (4.8 MB)\n",
      "   ---------------------------------------- 0.0/4.8 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.0/4.8 MB 8.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.8/4.8 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.4/4.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.7/4.8 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 4.5/4.8 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.8/4.8 MB 4.2 MB/s  0:00:01\n",
      "Downloading autoray-0.7.2-py3-none-any.whl (930 kB)\n",
      "   ---------------------------------------- 0.0/930.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 930.8/930.8 kB 4.3 MB/s  0:00:00\n",
      "Downloading pennylane_lightning-0.42.0-cp310-cp310-win_amd64.whl (6.6 MB)\n",
      "   ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/6.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.0/6.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.1/6.6 MB 3.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.6/6.6 MB 3.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.1/6.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.1/6.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 4.2/6.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.2/6.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.2/6.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.2/6.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.7/6.6 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.5/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.3/6.6 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.6/6.6 MB 2.2 MB/s  0:00:02\n",
      "Downloading scipy_openblas32-0.3.30.0.4-py3-none-win_amd64.whl (7.1 MB)\n",
      "   ---------------------------------------- 0.0/7.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.0/7.1 MB 6.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.0/7.1 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.1/7.1 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.9/7.1 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.1/7.1 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.1/7.1 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.1/7.1 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.1/7.1 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 4.5/7.1 MB 543.4 kB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 5.2/7.1 MB 632.5 kB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 5.2/7.1 MB 632.5 kB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 5.2/7.1 MB 632.5 kB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 5.2/7.1 MB 632.5 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 5.5/7.1 MB 598.2 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 6.6/7.1 MB 697.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.1/7.1 MB 745.3 kB/s  0:00:09\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading autograd-1.8.0-py3-none-any.whl (51 kB)\n",
      "Downloading cachetools-6.2.1-py3-none-any.whl (11 kB)\n",
      "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 1.0/1.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 4.1 MB/s  0:00:00\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: appdirs, wheel, tomlkit, termcolor, scipy-openblas32, networkx, gast, cachetools, autoray, autograd, astunparse, diastatic-malt, pennylane-lightning, pennylane\n",
      "\n",
      "   -- -------------------------------------  1/14 [wheel]\n",
      "   ----- ----------------------------------  2/14 [tomlkit]\n",
      "   ----------- ----------------------------  4/14 [scipy-openblas32]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   -------------- -------------------------  5/14 [networkx]\n",
      "   ---------------------- -----------------  8/14 [autoray]\n",
      "   ------------------------- --------------  9/14 [autograd]\n",
      "   ------------------------- --------------  9/14 [autograd]\n",
      "   ------------------------------- -------- 11/14 [diastatic-malt]\n",
      "   ------------------------------- -------- 11/14 [diastatic-malt]\n",
      "   ------------------------------- -------- 11/14 [diastatic-malt]\n",
      "   ---------------------------------- ----- 12/14 [pennylane-lightning]\n",
      "   ---------------------------------- ----- 12/14 [pennylane-lightning]\n",
      "   ---------------------------------- ----- 12/14 [pennylane-lightning]\n",
      "   ---------------------------------- ----- 12/14 [pennylane-lightning]\n",
      "   ---------------------------------- ----- 12/14 [pennylane-lightning]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ------------------------------------- -- 13/14 [pennylane]\n",
      "   ---------------------------------------- 14/14 [pennylane]\n",
      "\n",
      "Successfully installed appdirs-1.4.4 astunparse-1.6.3 autograd-1.8.0 autoray-0.7.2 cachetools-6.2.1 diastatic-malt-2.15.2 gast-0.6.0 networkx-3.4.2 pennylane-0.42.3 pennylane-lightning-0.42.0 scipy-openblas32-0.3.30.0.4 termcolor-3.1.0 tomlkit-0.13.3 wheel-0.45.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pennylane"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
